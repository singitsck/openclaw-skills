#!/usr/bin/env python3
"""
é¦™æ¸¯éŠ€è¡Œ/ä¿¡ç”¨å¡è²¡å‹™è‡ªå‹•åŒ– Workflow
è™•ç† Yahoo Mail çš„æœˆçµå–®èˆ‡äº¤æ˜“é€šçŸ¥
"""

import os
import sys
import imaplib
import email
import email.policy
import re
import csv
import json
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import base64
import tempfile

# Configuration
FINANCE_DIR = Path.home() / ".finance"
RAW_DIR = FINANCE_DIR / "raw"
PROCESSED_DIR = FINANCE_DIR / "processed"
REPORTS_DIR = FINANCE_DIR / "reports"
CONFIG_FILE = FINANCE_DIR / "config.json"

# Bank domains to search
BANK_DOMAINS = [
    # é¦™æ¸¯ä¸»è¦éŠ€è¡Œ
    "@hsbc.com.hk",
    "@notification.hsbc.com.hk",
    "@informationservices.hsbc.com.hk",
    "@citi.com",
    "@standardchartered.com.hk",
    "@dbs.com",
    "@boa.com",
    "@hangseng.com",
    "@bankcomm.com.hk",
    "@icbcasia.com",
    "@boc.com.hk",
    "@bochk.com",
    "@za.group",
    "@mox.com",
    # æ—¥æœ¬/äºæ´²éŠ€è¡Œ
    "@aeon.com.hk",
    # æ”¯ä»˜å¹³å°
    "@alipay.com",
    "@mail.alipay.com",
    "@wechatpay.com",
    "@wechat.com",
    "@tenpay.com",
    # å•†å®¶äº¤æ˜“é€šçŸ¥
    "@email.apple.com",
    "@steampowered.com",
]

# Search keywords
KEYWORDS = [
    "æœˆçµå–®", "e-Statement", "å°å¸³å–®", "é›»å­æœˆçµå–®",
    "Statement", "Transaction Summary", "transaction alert",
    "credit card statement", "éŠ€è¡Œæœˆçµå–®",
    "Transaction Alert", "äº¤æ˜“æç¤º", "Payment Confirmation",
    "Receipt", "æ”¶æ“š", "Purchase", "Order Confirmation",
    "ç›´æ¥æ‰£è³¬", "Direct Debit", "e-Statement Alert",
    # Alipay / WeChat Pay
    "æ”¯ä»˜å¯¶", "Alipay", "äº¤æ˜“æˆåŠŸ", "ä»˜æ¬¾æˆåŠŸ",
    "å¾®ä¿¡æ”¯ä»˜", "WeChat Pay", "è½‰è³¬", "äº¤æ˜“å®Œæˆ",
    "æ¶ˆè²»", "æ”¯ä»˜æˆåŠŸ", "æ‰£æ¬¾æˆåŠŸ"
]

# Category rules
CATEGORY_RULES = {
    "é£²é£Ÿ": ["é¤å»³", "food", "cafe", "éº¥ç•¶å‹", "mcdonald", "kfc", "pizza", "starbucks",
            "coffee", "restaurant", "é£Ÿ", "é£¯", "èŒ¶é¤å»³", "å¤§å®¶æ¨‚", "å¤§å¿«æ´»", "ç¾å¿ƒ"],
    "äº¤é€š": ["mtr", "taxi", "çš„å£«", "octopus", "fuel", "petrol", "shell", "esso",
            "mobil", "parking", "åœè»Šå ´", "æ¸¯éµ", "åœ°éµ", "å·´å£«", "uber"],
    "å¨›æ¨‚è³¼ç‰©": ["netflix", "spotify", "apple", "amazon", "æ·˜å¯¶", "taobao",
               "disney", "youtube", "steam", "game", "cinema", "æˆ²é™¢", "é›»å½±"],
    "è¶…å¸‚": ["è¶…å¸‚", "supermarket", "parknshop", "wellcome", "marketplace",
            "360", "jasons", "citysuper"],
    "é†«ç™‚": ["é†«é™¢", "clinic", "doctor", "pharmacy", "è¬å¯§", "mannings",
            "å±ˆè‡£æ°", "watsons", "é†«ç”Ÿ", "ç‰™é†«"],
    "æ°´é›»ç…¤": ["ä¸­é›»", "clp", "æ¸¯ç‡ˆ", "hke", "ç…¤æ°£", "towngas", "å¯¬é »",
             "broadband", "phone bill", "é›»è©±è²»"],
}


def load_config() -> Dict:
    """Load configuration from file"""
    if CONFIG_FILE.exists():
        with open(CONFIG_FILE, "r") as f:
            return json.load(f)
    return {}


def save_config(config: Dict):
    """Save configuration to file"""
    CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(CONFIG_FILE, "w") as f:
        json.dump(config, f, indent=2)


def connect_imap(email_addr: str, app_password: str) -> imaplib.IMAP4_SSL:
    """Connect to Yahoo Mail via IMAP"""
    print(f"ğŸ”— Connecting to Yahoo Mail IMAP...")
    mail = imaplib.IMAP4_SSL("imap.mail.yahoo.com", 993)
    mail.login(email_addr, app_password)
    print(f"âœ… IMAP login successful")
    return mail


def search_bank_emails(mail: imaplib.IMAP4_SSL, since_date: str, before_date: str) -> List[str]:
    """
    Search for bank/credit card emails
    since_date and before_date format: DD-MMM-YYYY
    """
    mail.select("inbox")

    # Build search criteria
    # Yahoo IMAP supports OR and FROM searches
    from_criteria = []
    for domain in BANK_DOMAINS:
        domain_clean = domain.lstrip("@")
        from_criteria.append(f'FROM "{domain_clean}"')

    # Search for emails from bank domains within date range
    # Using SENTSINCE and SENTBEFORE for date filtering
    search_query = f'(SENTSINCE {since_date} SENTBEFORE {before_date})'

    print(f"ğŸ” Searching: {search_query}")
    status, messages = mail.search(None, search_query)

    if status != "OK":
        print(f"âš ï¸ Search failed: {status}")
        return []

    email_ids = messages[0].decode().split()
    print(f"ğŸ“§ Found {len(email_ids)} emails from bank domains")
    return email_ids


def filter_by_keywords(mail: imaplib.IMAP4_SSL, email_ids: List[str]) -> List[Tuple[str, Dict]]:
    """Filter emails by subject/body keywords"""
    matching = []

    for eid in email_ids:
        status, msg_data = mail.fetch(eid, "(RFC822)")
        if status != "OK":
            continue

        msg = email.message_from_bytes(msg_data[0][1], policy=email.policy.default)
        subject = msg["Subject"] or ""

        # Check if subject contains any keyword
        subject_lower = subject.lower()
        for keyword in KEYWORDS:
            if keyword.lower() in subject_lower:
                matching.append((eid, {
                    "subject": subject,
                    "from": msg["From"],
                    "date": msg["Date"],
                    "keyword_matched": keyword
                }))
                break

    print(f"ğŸ¯ {len(matching)} emails match keywords")
    return matching


def extract_email_content(msg) -> str:
    """Extract text content from email (HTML or plain text)"""
    content = ""
    
    if msg.is_multipart():
        for part in msg.walk():
            content_type = part.get_content_type()
            content_disposition = str(part.get("Content-Disposition", ""))
            
            # Skip attachments
            if "attachment" in content_disposition:
                continue
                
            if content_type == "text/plain":
                try:
                    payload = part.get_payload(decode=True)
                    if payload:
                        charset = part.get_content_charset() or "utf-8"
                        content += payload.decode(charset, errors="ignore") + "\n"
                except:
                    pass
            elif content_type == "text/html":
                try:
                    payload = part.get_payload(decode=True)
                    if payload:
                        charset = part.get_content_charset() or "utf-8"
                        html = payload.decode(charset, errors="ignore")
                        # Simple HTML to text conversion
                        text = re.sub(r'<[^>]+>', ' ', html)
                        text = re.sub(r'\s+', ' ', text)
                        content += text + "\n"
                except:
                    pass
    else:
        # Single part email
        try:
            payload = msg.get_payload(decode=True)
            if payload:
                charset = msg.get_content_charset() or "utf-8"
                content = payload.decode(charset, errors="ignore")
                if msg.get_content_type() == "text/html":
                    content = re.sub(r'<[^>]+>', ' ', content)
                    content = re.sub(r'\s+', ' ', content)
        except:
            pass
    
    return content


def download_attachments(mail: imaplib.IMAP4_SSL, email_ids: List[str], download_dir: Path) -> List[Path]:
    """Download PDF attachments from emails"""
    downloaded = []

    for eid in email_ids:
        status, msg_data = mail.fetch(eid, "(RFC822)")
        if status != "OK":
            continue

        msg = email.message_from_bytes(msg_data[0][1], policy=email.policy.default)
        subject = msg["Subject"] or "No Subject"
        date_str = msg["Date"] or ""

        # Clean subject for filename
        clean_subject = re.sub(r'[^\w\s-]', '', subject)[:50].strip()

        has_pdf_attachment = False
        if msg.is_multipart():
            for part in msg.walk():
                content_type = part.get_content_type()
                content_disposition = str(part.get("Content-Disposition", ""))

                if content_type == "application/pdf" or "attachment" in content_disposition:
                    has_pdf_attachment = True
                    filename = part.get_filename()
                    if not filename:
                        # Generate filename from subject
                        filename = f"{clean_subject}_{eid}.pdf"

                    # Ensure .pdf extension
                    if not filename.lower().endswith(".pdf"):
                        filename += ".pdf"

                    filepath = download_dir / filename

                    # Handle duplicates
                    counter = 1
                    original_filepath = filepath
                    while filepath.exists():
                        stem = original_filepath.stem
                        filepath = download_dir / f"{stem}_{counter}.pdf"
                        counter += 1

                    payload = part.get_payload(decode=True)
                    if payload:
                        with open(filepath, "wb") as f:
                            f.write(payload)
                        downloaded.append(filepath)
                        print(f"  â¬‡ï¸ Downloaded PDF: {filepath.name}")

        # If no PDF attachment, save the email content as text for parsing
        if not has_pdf_attachment:
            content = extract_email_content(msg)
            if content.strip():
                txt_filename = f"{clean_subject}_{eid}.txt"
                txt_path = download_dir / txt_filename
                counter = 1
                while txt_path.exists():
                    txt_path = download_dir / f"{clean_subject}_{eid}_{counter}.txt"
                    counter += 1
                
                # Save content with metadata header
                email_date = msg["Date"] or ""
                from_addr = msg["From"] or ""
                email_metadata = f"EMAIL_METADATA\nDate: {email_date}\nFrom: {from_addr}\nSubject: {subject}\n===CONTENT===\n"
                
                with open(txt_path, "w", encoding="utf-8") as f:
                    f.write(email_metadata + content)
                downloaded.append(txt_path)
                print(f"  ğŸ’¾ Saved email content: {txt_path.name}")

    return downloaded


def parse_content_to_text(file_path: Path) -> Tuple[str, str]:
    """Extract text from PDF or read text file, return content and email date"""
    email_date = ""
    
    if file_path.suffix.lower() == '.txt':
        # Read text file directly
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract email date from metadata if present
        if content.startswith("EMAIL_METADATA"):
            date_match = re.search(r'Date:\s*(.+?)\n', content)
            if date_match:
                email_date = date_match.group(1).strip()
            # Remove metadata header for parsing
            content = re.sub(r'^EMAIL_METADATA[\s\S]*?===CONTENT===\n', '', content)
        
        return content, email_date
    
    # Parse PDF
    try:
        # Try pdfplumber first (better for tables)
        import pdfplumber
        text = ""
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                text += page.extract_text() or ""
        return text, ""
    except ImportError:
        # Fallback to pdftotext (poppler)
        result = subprocess.run(
            ["pdftotext", "-layout", str(file_path), "-"],
            capture_output=True,
            text=True
        )
        return result.stdout, ""


def extract_transactions_from_text(text: str, source_file: str, email_date: str = "") -> List[Dict]:
    """
    Extract transactions from text content
    Supports various HK bank formats including BOC, ZA Bank, etc.
    """
    transactions = []
    
    # Parse email date if available
    parsed_date = "2026-01-15"  # Default
    if email_date:
        try:
            # Try to parse various date formats
            # Example: "Fri, 10 Jan 2026 08:30:00 +0000"
            date_match = re.search(r'(\d{1,2})\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+(\d{4})', email_date)
            if date_match:
                day, month_str, year = date_match.groups()
                months = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06',
                         'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}
                month = months.get(month_str, '01')
                parsed_date = f"{year}-{month}-{day.zfill(2)}"
        except:
            pass
    
    # === BOC (ä¸­éŠ€ä¿¡ç”¨å¡) Format ===
    # Pattern: å•†æˆ¶åç¨±ï¼šXXXX äº¤æ˜“é‡‘é¡ï¼šHKD/USD XX.XX
    boc_patterns = [
        # Chinese format
        r'å•†æˆ¶åç¨±[ï¼š:]\s*([^\n]+?)\s*äº¤æ˜“é‡‘é¡[ï¼š:]\s*(HKD|USD)\s*([\d.]+)',
        # English format
        r'Merchant Name[ï¼š:]\s*([^\n]+?)\s*Transaction Amount[ï¼š:]\s*(HKD|USD)\s*([\d.]+)',
    ]
    
    for pattern in boc_patterns:
        matches = re.finditer(pattern, text, re.IGNORECASE | re.DOTALL)
        for match in matches:
            merchant = match.group(1).strip()
            currency = match.group(2).upper()
            amount_str = match.group(3)
            
            try:
                amount = float(amount_str)
                # Create transaction key to avoid duplicates
                tx_key = f"{merchant}_{amount}_{currency}"
                if any(tx.get('_key') == tx_key for tx in transactions):
                    continue
                    
                tx = {
                    "æ—¥æœŸ": parsed_date,
                    "æè¿°": merchant[:80],
                    "é‡‘é¡": amount,
                    "å¹£åˆ¥": currency,
                    "é¡å‹": "æ”¯å‡º",
                    "å¡è™Ÿå¾Œå››ç¢¼": "",
                    "ä¾†æºæª”æ¡ˆ": source_file,
                    "_key": tx_key  # Temporary key for deduplication
                }
                transactions.append(tx)
            except (ValueError, IndexError):
                continue
    
    # Remove temporary keys
    for tx in transactions:
        tx.pop('_key', None)
    
    # === BOC Transaction Notification Format ===
    # Alternative format with more details
    boc_alt_pattern = r'æ‚¨çš„ä¸­éŠ€ä¿¡ç”¨å¡è³¬æˆ¶å·²å®Œæˆç›´æ¥æ‰£å¸³äº¤æ˜“.*?è©³æƒ…å¦‚ä¸‹[ï¼š:]\s*å•†æˆ¶åç¨±[ï¼š:]\s*([^\n]+?)\s*äº¤æ˜“é‡‘é¡[ï¼š:]\s*(HKD|USD)([\d.]+)'
    match = re.search(boc_alt_pattern, text, re.DOTALL | re.IGNORECASE)
    if match and not transactions:  # Only if no transactions found yet
        merchant = match.group(1).strip()
        currency = match.group(2).upper()
        amount_str = match.group(3)
        try:
            amount = float(amount_str)
            transactions.append({
                "æ—¥æœŸ": parsed_date,
                "æè¿°": merchant[:80],
                "é‡‘é¡": amount,
                "å¹£åˆ¥": currency,
                "é¡å‹": "æ”¯å‡º",
                "å¡è™Ÿå¾Œå››ç¢¼": "",
                "ä¾†æºæª”æ¡ˆ": source_file
            })
        except ValueError:
            pass
    
    # === HSBC Hong Kong Format ===
    # HSBC transaction alerts
    if 'hsbc' in source_file.lower():
        # Look for HKD/USD amounts
        hsbc_amount_pattern = r'(HKD|USD)\s*([\d,]+\.\d{2})'
        matches = re.finditer(hsbc_amount_pattern, text, re.IGNORECASE)
        for match in matches:
            try:
                currency = match.group(1).upper()
                amount_str = match.group(2).replace(',', '')
                amount = float(amount_str)
                
                # Try to find merchant
                merchant = "Transaction"
                # Look for merchant in nearby text
                start = max(0, match.start() - 200)
                end = min(len(text), match.end() + 200)
                nearby = text[start:end]
                
                # Common patterns for merchant
                merchant_patterns = [
                    r'(?:at|to|merchant|payee)[\s:]+([^\n,]{2,40})',
                    r'(?:from|via)[\s:]+([^\n,]{2,40})',
                ]
                for mp in merchant_patterns:
                    mm = re.search(mp, nearby, re.IGNORECASE)
                    if mm:
                        merchant = mm.group(1).strip()
                        break
                
                tx = {
                    "æ—¥æœŸ": parsed_date,
                    "æè¿°": f"HSBC: {merchant[:70]}",
                    "é‡‘é¡": amount,
                    "å¹£åˆ¥": currency,
                    "é¡å‹": "æ”¯å‡º",
                    "å¡è™Ÿå¾Œå››ç¢¼": "",
                    "ä¾†æºæª”æ¡ˆ": source_file
                }
                if not any(t.get('æè¿°') == tx['æè¿°'] and t.get('é‡‘é¡') == tx['é‡‘é¡'] for t in transactions):
                    transactions.append(tx)
            except (ValueError, IndexError):
                continue
    
    # === Alipay (æ”¯ä»˜å¯¶) Format ===
    # Alipay transaction notifications
    if 'alipay' in source_file.lower() or 'alipay.com' in text.lower() or 'æ”¯ä»˜å¯¶' in text:
        alipay_patterns = [
            # Chinese format: äº¤æ˜“é‡‘é¡ï¼šHKD 100.00
            r'(?:äº¤æ˜“|ä»˜æ¬¾|æ”¯ä»˜)(?:é‡‘é¡|é‡‘é¢)[ï¼š:]\s*(?:HKD|USD|CNY|RMB)?\s*([\d,]+\.\d{2})',
            # Alternative: HKD 100.00 å…ƒ
            r'(?:HKD|USD|CNY|RMB)\s*([\d,]+\.\d{2})\s*(?:å…ƒ)?',
        ]
        
        for pattern in alipay_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '')
                    amount = float(amount_str)
                    
                    # Detect currency
                    currency = "HKD"  # Default for HK
                    if "USD" in text[:match.start()]:
                        currency = "USD"
                    elif "CNY" in text[:match.start()] or "RMB" in text[:match.start()]:
                        currency = "CNY"
                    
                    # Extract merchant/product
                    merchant = "Alipay Payment"
                    # Look for merchant patterns
                    merchant_patterns = [
                        r'(?:å•†å®¶|å•†æˆ¶|å•†æˆ¶åç¨±|æ”¶æ¬¾æ–¹)[ï¼š:]\s*([^\n,]{2,40})',
                        r'(?:å•†å“æè¿°|å•†å“|æè¿°)[ï¼š:]\s*([^\n,]{2,40})',
                        r'(?:ä»˜æ¬¾çµ¦|æ”¯ä»˜çµ¦|è½‰è³¬çµ¦)\s*([^\n,]{2,40})',
                    ]
                    for mp in merchant_patterns:
                        mm = re.search(mp, text)
                        if mm:
                            merchant = mm.group(1).strip()
                            break
                    
                    tx = {
                        "æ—¥æœŸ": parsed_date,
                        "æè¿°": f"Alipay: {merchant[:70]}",
                        "é‡‘é¡": amount,
                        "å¹£åˆ¥": currency,
                        "é¡å‹": "æ”¯å‡º",
                        "å¡è™Ÿå¾Œå››ç¢¼": "",
                        "ä¾†æºæª”æ¡ˆ": source_file
                    }
                    if not any(t.get('æè¿°') == tx['æè¿°'] and t.get('é‡‘é¡') == tx['é‡‘é¡'] for t in transactions):
                        transactions.append(tx)
                except (ValueError, IndexError):
                    continue
    
    # === WeChat Pay (å¾®ä¿¡æ”¯ä»˜) Format ===
    # WeChat Pay transaction notifications
    if 'wechat' in source_file.lower() or 'wechatpay' in text.lower() or 'å¾®ä¿¡æ”¯ä»˜' in text:
        wechat_patterns = [
            # Chinese format: æ”¯ä»˜é‡‘é¡ï¼šHKD 50.00
            r'(?:æ”¯ä»˜|ä»˜æ¬¾|è½‰è³¬|æ¶ˆè²»)(?:é‡‘é¡|é‡‘é¢)[ï¼š:]\s*(?:HKD|USD|CNY|RMB)?\s*([\d,]+\.\d{2})',
            # Alternative: é‡‘é¡ HKD 50.00
            r'(?:é‡‘é¡|é‡‘é¢)[ï¼š:]\s*(?:HKD|USD|CNY|RMB)?\s*([\d,]+\.\d{2})',
            # Simple: HKD 50.00
            r'(?:HKD|USD|CNY|RMB)\s*([\d,]+\.\d{2})',
        ]
        
        for pattern in wechat_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '')
                    amount = float(amount_str)
                    
                    # Detect currency
                    currency = "HKD"
                    if "USD" in text[max(0, match.start()-20):match.start()]:
                        currency = "USD"
                    elif "CNY" in text[max(0, match.start()-20):match.start()] or "RMB" in text[max(0, match.start()-20):match.start()]:
                        currency = "CNY"
                    
                    # Extract merchant
                    merchant = "WeChat Pay"
                    # Look for merchant/store patterns
                    merchant_patterns = [
                        r'(?:å•†å®¶|å•†æˆ¶|å•†æˆ¶åç¨±|æ”¶æ¬¾æ–¹|å•†èˆ—)[ï¼š:]\s*([^\n,]{2,40})',
                        r'(?:å•†å“|æè¿°|å‚™è¨»)[ï¼š:]\s*([^\n,]{2,40})',
                        r'(?:ä»˜æ¬¾çµ¦|æ”¯ä»˜çµ¦|è½‰è³¬çµ¦|æƒç¢¼æ”¯ä»˜)\s*([^\n,]{2,40})',
                    ]
                    for mp in merchant_patterns:
                        mm = re.search(mp, text)
                        if mm:
                            merchant = mm.group(1).strip()
                            break
                    
                    # Check if it's a transfer (è½‰è³¬) vs payment
                    tx_type = "æ”¯å‡º"
                    if any(kw in text for kw in ['è½‰è³¬', 'è½‰è³¬', 'ç´…åŒ…', 'æ”¶åˆ°']):
                        if 'æ”¶åˆ°' in text or 'è½‰å…¥' in text:
                            tx_type = "æ”¶å…¥"
                    
                    tx = {
                        "æ—¥æœŸ": parsed_date,
                        "æè¿°": f"WeChat Pay: {merchant[:70]}",
                        "é‡‘é¡": amount,
                        "å¹£åˆ¥": currency,
                        "é¡å‹": tx_type,
                        "å¡è™Ÿå¾Œå››ç¢¼": "",
                        "ä¾†æºæª”æ¡ˆ": source_file
                    }
                    if not any(t.get('æè¿°') == tx['æè¿°'] and t.get('é‡‘é¡') == tx['é‡‘é¡'] for t in transactions):
                        transactions.append(tx)
                except (ValueError, IndexError):
                    continue
    
    # === Apple Receipt Format ===
    # Apple receipts and billing emails (skip if already extracted by BOC)
    is_boc_email = 'boc' in source_file.lower() or 'ä¸­éŠ€' in source_file.lower() or 'å•†æˆ¶åç¨±' in text
    if ('apple' in source_file.lower() or 'apple.com' in text.lower() or 'apple.com/bill' in text.lower()) and not is_boc_email:
        # Look for amount patterns
        apple_amount_pattern = r'(HKD|USD|US\$)\s*([\d,]+\.\d{2})'
        match = re.search(apple_amount_pattern, text, re.IGNORECASE)
        if match:
            try:
                currency = match.group(1).upper().replace('US$', 'USD')
                amount_str = match.group(2).replace(',', '')
                amount = float(amount_str)
                
                # Determine product
                product = "Purchase"
                # Check for subscription keywords
                if any(kw in text.lower() for kw in ['subscription', 'è¨‚é–±', 'icloud', 'apple music', 'apple tv', 'apple one']):
                    product = "Subscription"
                
                # Try to find specific product name
                product_match = re.search(r'(?:for|product|item|app|game)[\s:]+([^\n,]{2,50}?)(?:\n|$|,)', text, re.IGNORECASE)
                if product_match:
                    product = product_match.group(1).strip()[:50]
                
                tx = {
                    "æ—¥æœŸ": parsed_date,
                    "æè¿°": f"Apple: {product[:70]}",
                    "é‡‘é¡": amount,
                    "å¹£åˆ¥": currency if currency != 'US$' else 'USD',
                    "é¡å‹": "æ”¯å‡º",
                    "å¡è™Ÿå¾Œå››ç¢¼": "",
                    "ä¾†æºæª”æ¡ˆ": source_file
                }
                if not any(t.get('æè¿°') == tx['æè¿°'] and t.get('é‡‘é¡') == tx['é‡‘é¡'] for t in transactions):
                    transactions.append(tx)
            except (ValueError, IndexError):
                pass  # Skip on error, no loop to continue
    
    # === Steam Purchase Format ===
    # Steam emails have "Purchase Confirmation" and game names
    if "steampowered.com" in text.lower() or "steam" in source_file.lower():
        steam_patterns = [
            r'(?:Total|ç¸½è¨ˆ)[ï¼š:]\s*(?:HKD|USD|US\$)?\s*([\d.]+)',
            r'(?:HKD|USD|US\$)\s*([\d.]+)\s+(?:Total|ç¸½è¨ˆ)',
        ]
        
        for pattern in steam_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                try:
                    amount_str = match.group(1).replace(',', '')
                    amount = float(amount_str)
                    
                    # Extract game/app name
                    game_match = re.search(r'(?:éŠæˆ²|Game|Item)[ï¼š:]\s*([^\n]{2,50})', text, re.IGNORECASE)
                    game = game_match.group(1).strip() if game_match else "Steam Purchase"
                    
                    tx = {
                        "æ—¥æœŸ": parsed_date,
                        "æè¿°": f"Steam: {game[:70]}",
                        "é‡‘é¡": amount,
                        "å¹£åˆ¥": "HKD",
                        "é¡å‹": "æ”¯å‡º",
                        "å¡è™Ÿå¾Œå››ç¢¼": "",
                        "ä¾†æºæª”æ¡ˆ": source_file
                    }
                    if not any(t['æè¿°'] == tx['æè¿°'] and t['é‡‘é¡'] == tx['é‡‘é¡'] for t in transactions):
                        transactions.append(tx)
                    break  # Only take first match for Steam
                except (ValueError, IndexError):
                    continue
    
    # === AEON Credit Card Format ===
    # AEON transaction notifications
    aeon_patterns = [
        r'(?:å•†æˆ¶|Merchant)[ï¼š:]\s*([^\n]{2,40})[^\n]*(?:é‡‘é¡|Amount)[ï¼š:]\s*(?:HKD)?\s*([\d,]+\.\d{2})',
        r'(?:AEON|aeon)[^\n]*(?:HKD)\s*([\d,]+\.\d{2})[^\n]*(?:at|@)\s*([^\n]{2,40})',
    ]
    
    for pattern in aeon_patterns:
        matches = re.finditer(pattern, text, re.IGNORECASE | re.DOTALL)
        for match in matches:
            try:
                # Pattern may have groups in different order
                group1 = match.group(1).strip()
                group2 = match.group(2).replace(',', '')
                
                # Determine which is amount and which is merchant
                try:
                    amount = float(group2)
                    merchant = group1
                except ValueError:
                    amount = float(group1.replace(',', ''))
                    merchant = group2
                
                tx = {
                    "æ—¥æœŸ": parsed_date,
                    "æè¿°": f"AEON: {merchant[:70]}",
                    "é‡‘é¡": amount,
                    "å¹£åˆ¥": "HKD",
                    "é¡å‹": "æ”¯å‡º",
                    "å¡è™Ÿå¾Œå››ç¢¼": "",
                    "ä¾†æºæª”æ¡ˆ": source_file
                }
                if not any(t['æè¿°'] == tx['æè¿°'] and t['é‡‘é¡'] == tx['é‡‘é¡'] for t in transactions):
                    transactions.append(tx)
            except (ValueError, IndexError):
                continue
    
    # === ZA Bank / Statement Table Format ===
    # Look for table-like transaction data
    za_patterns = [
        r'(\d{4}-\d{2}-\d{2})\s+([\u4e00-\u9fa5\w\s./@-]+?)\s+(-?[\d,]+\.\d{2})',
        r'(\d{2}/\d{2}/\d{4})\s+([\u4e00-\u9fa5\w\s./@-]+?)\s+(-?[\d,]+\.\d{2})',
    ]
    
    for pattern in za_patterns:
        matches = re.finditer(pattern, text)
        for match in matches:
            try:
                date_str = match.group(1)
                desc = match.group(2).strip()
                amount_str = match.group(3).replace(',', '')
                
                # Determine if credit or debit
                is_debit = '-' in amount_str or any(x in desc.lower() for x in ['æ”¯å‡º', 'debit', 'ä»˜æ¬¾'])
                amount = float(amount_str.replace('-', ''))
                
                # Standardize date format
                if '/' in date_str:
                    parts = date_str.split('/')
                    if len(parts[2]) == 4:  # DD/MM/YYYY
                        date_str = f"{parts[2]}-{parts[1]}-{parts[0]}"
                
                transactions.append({
                    "æ—¥æœŸ": date_str,
                    "æè¿°": desc[:80],
                    "é‡‘é¡": amount,
                    "å¹£åˆ¥": "HKD",
                    "é¡å‹": "æ”¯å‡º" if is_debit else "æ”¶å…¥",
                    "å¡è™Ÿå¾Œå››ç¢¼": "",
                    "ä¾†æºæª”æ¡ˆ": source_file
                })
            except (ValueError, IndexError):
                continue
    
    return transactions


def categorize_transaction(description: str) -> str:
    """Categorize transaction based on description"""
    desc_lower = description.lower()

    for category, keywords in CATEGORY_RULES.items():
        for keyword in keywords:
            if keyword.lower() in desc_lower:
                return category

    return "å¾…ç¢ºèª"


def detect_subscriptions(transactions: List[Dict]) -> List[Dict]:
    """Detect potential subscriptions (same amount + description pattern)"""
    # Group by amount and similar description
    amount_groups = {}
    for tx in transactions:
        key = (round(tx["é‡‘é¡"], 2), tx["æè¿°"][:15].lower())
        if key not in amount_groups:
            amount_groups[key] = []
        amount_groups[key].append(tx)

    subscriptions = []
    for key, txs in amount_groups.items():
        if len(txs) >= 2:  # Same amount appears multiple times
            subscriptions.append({
                "æè¿°": txs[0]["æè¿°"][:30],
                "é‡‘é¡": key[0],
                "å‡ºç¾æ¬¡æ•¸": len(txs),
                "é¡å‹": "æ½›åœ¨è¨‚é–±"
            })

    return subscriptions


def generate_csv(transactions: List[Dict], output_path: Path):
    """Generate CSV file from transactions"""
    if not transactions:
        print(f"âš ï¸ No transactions to write")
        return

    # Add category
    for tx in transactions:
        tx["é¡åˆ¥"] = categorize_transaction(tx["æè¿°"])

    with open(output_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=transactions[0].keys())
        writer.writeheader()
        writer.writerows(transactions)

    print(f"ğŸ’¾ CSV saved: {output_path}")


def generate_statistics(transactions: List[Dict]) -> Dict:
    """Generate financial statistics"""
    if not transactions:
        return {}

    income = [tx for tx in transactions if tx["é¡å‹"] == "æ”¶å…¥"]
    expense = [tx for tx in transactions if tx["é¡å‹"] == "æ”¯å‡º"]

    total_income = sum(tx["é‡‘é¡"] for tx in income)
    total_expense = sum(tx["é‡‘é¡"] for tx in expense)

    # Category breakdown
    categories = {}
    for tx in expense:
        cat = tx.get("é¡åˆ¥", "å¾…ç¢ºèª")
        categories[cat] = categories.get(cat, 0) + tx["é‡‘é¡"]

    # Top 5 expenses
    top_expenses = sorted(expense, key=lambda x: x["é‡‘é¡"], reverse=True)[:5]

    # Subscriptions
    subscriptions = detect_subscriptions(transactions)

    return {
        "ç¸½æ”¶å…¥": total_income,
        "ç¸½æ”¯å‡º": total_expense,
        "æ·¨é¡": total_income - total_expense,
        "äº¤æ˜“ç­†æ•¸": len(transactions),
        "æ”¶å…¥ç­†æ•¸": len(income),
        "æ”¯å‡ºç­†æ•¸": len(expense),
        "é¡åˆ¥åˆ†å¸ƒ": categories,
        "æœ€å¤§æ”¯å‡ºTop5": [
            {"æè¿°": tx["æè¿°"][:40], "é‡‘é¡": tx["é‡‘é¡"], "æ—¥æœŸ": tx["æ—¥æœŸ"]}
            for tx in top_expenses
        ],
        "æ½›åœ¨è¨‚é–±": subscriptions
    }


def generate_html_report(transactions: List[Dict], stats: Dict, month: str, output_path: Path):
    """Generate HTML report with simple charts"""

    # Category colors
    colors = {
        "é£²é£Ÿ": "#FF6B6B",
        "äº¤é€š": "#4ECDC4",
        "å¨›æ¨‚è³¼ç‰©": "#45B7D1",
        "è¶…å¸‚": "#96CEB4",
        "é†«ç™‚": "#FFEAA7",
        "æ°´é›»ç…¤": "#DDA0DD",
        "å¾…ç¢ºèª": "#B2BEC3"
    }

    # Build category chart data
    cat_data = stats.get("é¡åˆ¥åˆ†å¸ƒ", {})
    cat_labels = json.dumps(list(cat_data.keys()))
    cat_values = json.dumps(list(cat_data.values()))
    cat_colors = json.dumps([colors.get(k, "#B2BEC3") for k in cat_data.keys()])

    html = f"""<!DOCTYPE html>
<html lang="zh-HK">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è²¡å‹™å ±è¡¨ {month}</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
        }}
        h1 {{
            text-align: center;
            color: white;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }}
        .card {{
            background: white;
            border-radius: 16px;
            padding: 24px;
            margin-bottom: 20px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
        }}
        .summary-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 16px;
            margin-bottom: 20px;
        }}
        .summary-item {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 12px;
            text-align: center;
        }}
        .summary-item.Expense {{
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        }}
        .summary-item.Income {{
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        }}
        .summary-item.Net {{
            background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%);
        }}
        .summary-label {{
            font-size: 0.9em;
            opacity: 0.9;
            margin-bottom: 8px;
        }}
        .summary-value {{
            font-size: 1.8em;
            font-weight: bold;
        }}
        .chart-container {{
            position: relative;
            height: 300px;
            margin: 20px 0;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin-top: 16px;
        }}
        th, td {{
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #eee;
        }}
        th {{
            background: #f8f9fa;
            font-weight: 600;
            color: #333;
        }}
        tr:hover {{
            background: #f8f9fa;
        }}
        .amount-expense {{ color: #e74c3c; }}
        .amount-income {{ color: #27ae60; }}
        .alert {{
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 12px 16px;
            margin: 10px 0;
            border-radius: 4px;
        }}
        .alert-warning {{
            background: #f8d7da;
            border-left-color: #dc3545;
        }}
        .category-tag {{
            display: inline-block;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 500;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ’° {month} è²¡å‹™å ±è¡¨</h1>

        <div class="card">
            <h2>ğŸ“Š æ”¶æ”¯æ‘˜è¦</h2>
            <div class="summary-grid">
                <div class="summary-item Income">
                    <div class="summary-label">ç¸½æ”¶å…¥</div>
                    <div class="summary-value">${stats.get('ç¸½æ”¶å…¥', 0):,.2f}</div>
                </div>
                <div class="summary-item Expense">
                    <div class="summary-label">ç¸½æ”¯å‡º</div>
                    <div class="summary-value">${stats.get('ç¸½æ”¯å‡º', 0):,.2f}</div>
                </div>
                <div class="summary-item Net">
                    <div class="summary-label">æ·¨é¡</div>
                    <div class="summary-value">${stats.get('æ·¨é¡', 0):,.2f}</div>
                </div>
                <div class="summary-item">
                    <div class="summary-label">äº¤æ˜“ç­†æ•¸</div>
                    <div class="summary-value">{stats.get('äº¤æ˜“ç­†æ•¸', 0)}</div>
                </div>
            </div>
        </div>

        <div class="card">
            <h2>ğŸ“ˆ æ”¯å‡ºé¡åˆ¥åˆ†å¸ƒ</h2>
            <div class="chart-container">
                <canvas id="categoryChart"></canvas>
            </div>
        </div>

        <div class="card">
            <h2>ğŸ”¥ æœ€å¤§æ”¯å‡º Top 5</h2>
            <table>
                <thead>
                    <tr>
                        <th>æ—¥æœŸ</th>
                        <th>æè¿°</th>
                        <th>é‡‘é¡</th>
                    </tr>
                </thead>
                <tbody>
                    {''.join(f"<tr><td>{tx['æ—¥æœŸ']}</td><td>{tx['æè¿°']}</td><td class='amount-expense'>${tx['é‡‘é¡']:,.2f}</td></tr>" for tx in stats.get('æœ€å¤§æ”¯å‡ºTop5', []))}
                </tbody>
            </table>
        </div>
"""

    # Add subscriptions alert if any
    subs = stats.get("æ½›åœ¨è¨‚é–±", [])
    if subs:
        html += """
        <div class="card">
            <h2>âš ï¸ æ½›åœ¨é‡è¤‡è¨‚é–±</h2>
"""
        for sub in subs:
            html += f"""
            <div class="alert alert-warning">
                <strong>{sub['æè¿°']}</strong> - ${sub['é‡‘é¡']:,.2f} (å‡ºç¾ {sub['å‡ºç¾æ¬¡æ•¸']} æ¬¡)
            </div>
"""
        html += "</div>"

    html += f"""
        <div class="card">
            <h2>ğŸ“ äº¤æ˜“æ˜ç´°</h2>
            <table>
                <thead>
                    <tr>
                        <th>æ—¥æœŸ</th>
                        <th>æè¿°</th>
                        <th>é¡åˆ¥</th>
                        <th>é¡å‹</th>
                        <th>é‡‘é¡</th>
                    </tr>
                </thead>
                <tbody>
                    {''.join(f"<tr><td>{tx['æ—¥æœŸ']}</td><td>{tx['æè¿°']}</td><td><span class='category-tag' style='background:{colors.get(tx.get('é¡åˆ¥','å¾…ç¢ºèª'),'#B2BEC3')}20;color:{colors.get(tx.get('é¡åˆ¥','å¾…ç¢ºèª'),'#B2BEC3')}'>{tx.get('é¡åˆ¥','å¾…ç¢ºèª')}</span></td><td>{tx['é¡å‹']}</td><td class='{'amount-income' if tx['é¡å‹']=='æ”¶å…¥' else 'amount-expense'}'>${tx['é‡‘é¡']:,.2f}</td></tr>" for tx in transactions[:50])}
                </tbody>
            </table>
            {'<p style="text-align:center;color:#999;margin-top:16px;">... é‚„æœ‰ ' + str(len(transactions)-50) + ' ç­†äº¤æ˜“</p>' if len(transactions) > 50 else ''}
        </div>
    </div>

    <script>
        const ctx = document.getElementById('categoryChart').getContext('2d');
        new Chart(ctx, {{
            type: 'doughnut',
            data: {{
                labels: {cat_labels},
                datasets: [{{
                    data: {cat_values},
                    backgroundColor: {cat_colors},
                    borderWidth: 2,
                    borderColor: '#fff'
                }}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: false,
                plugins: {{
                    legend: {{
                        position: 'bottom',
                        labels: {{
                            padding: 20,
                            font: {{ size: 12 }}
                        }}
                    }}
                }}
            }}
        }});
    </script>
</body>
</html>
"""

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(html)

    print(f"ğŸ“Š HTML report saved: {output_path}")


def send_discord_summary(stats: Dict, month: str, csv_preview: str):
    """Generate Discord summary message"""
    emoji = "ğŸ’™"

    message = f"""{emoji} **{month} è²¡å‹™æœˆå ±** {emoji}

ğŸ“Š **æ”¶æ”¯æ‘˜è¦**
â€¢ ç¸½æ”¶å…¥: ${stats.get('ç¸½æ”¶å…¥', 0):,.2f}
â€¢ ç¸½æ”¯å‡º: ${stats.get('ç¸½æ”¯å‡º', 0):,.2f}
â€¢ æ·¨é¡: ${stats.get('æ·¨é¡', 0):,.2f}
â€¢ äº¤æ˜“ç­†æ•¸: {stats.get('äº¤æ˜“ç­†æ•¸', 0)}

ğŸ”¥ **æœ€å¤§æ”¯å‡º Top 3**
"""
    for i, tx in enumerate(stats.get('æœ€å¤§æ”¯å‡ºTop5', [])[:3], 1):
        message += f"{i}. {tx['æè¿°'][:25]} - ${tx['é‡‘é¡']:,.2f}\n"

    # Category breakdown
    cats = stats.get("é¡åˆ¥åˆ†å¸ƒ", {})
    if cats:
        message += "\nğŸ“ˆ **æ”¯å‡ºé¡åˆ¥**\n"
        for cat, amount in sorted(cats.items(), key=lambda x: x[1], reverse=True)[:5]:
            pct = (amount / stats.get('ç¸½æ”¯å‡º', 1)) * 100 if stats.get('ç¸½æ”¯å‡º', 0) > 0 else 0
            message += f"â€¢ {cat}: ${amount:,.2f} ({pct:.1f}%)\n"

    # Subscriptions warning
    subs = stats.get("æ½›åœ¨è¨‚é–±", [])
    if subs:
        message += f"\nâš ï¸ **è¨‚é–±è­¦ç¤º**: æª¢æ¸¬åˆ° {len(subs)} é …æ½›åœ¨é‡è¤‡è¨‚é–±\n"

    message += f"\nğŸ“ è©³ç´°å ±è¡¨: `~/.finance/reports/{month}.html`"

    return message


def main():
    import argparse
    parser = argparse.ArgumentParser(description="é¦™æ¸¯éŠ€è¡Œè²¡å‹™è‡ªå‹•åŒ– Workflow")
    parser.add_argument("--month", help="è™•ç†æœˆä»½ (YYYY-MMæ ¼å¼ï¼Œé»˜èªä¸Šå€‹æœˆ)")
    parser.add_argument("--test", action="store_true", help="æ¸¬è©¦æ¨¡å¼ï¼šåªè™•ç†å‰10è¡Œä¸¦è¼¸å‡ºé è¦½")
    parser.add_argument("--download-only", action="store_true", help="åƒ…ä¸‹è¼‰é™„ä»¶ï¼Œä¸è§£æ")
    args = parser.parse_args()

    # Determine target month
    if args.month:
        target_month = args.month
    else:
        last_month = datetime.now().replace(day=1) - timedelta(days=1)
        target_month = last_month.strftime("%Y-%m")

    print(f"ğŸ—“ï¸ è™•ç†æœˆä»½: {target_month}")

    # Load config
    config = load_config()
    if not config.get("email") or not config.get("app_password"):
        print("âŒ è«‹å…ˆè¨­å®š Yahoo Mail å¸³è™Ÿå’Œ App Password")
        print("   ç·¨è¼¯: ~/.finance/config.json")
        print(json.dumps({"email": "your@yahoo.com", "app_password": "xxxx xxxx xxxx xxxx"}, indent=2))
        sys.exit(1)

    # Calculate date range for email search
    year, month = map(int, target_month.split("-"))
    month_start = datetime(year, month, 1)
    if month == 12:
        next_month_start = datetime(year + 1, 1, 1)
    else:
        next_month_start = datetime(year, month + 1, 1)

    since_date = month_start.strftime("%d-%b-%Y")
    before_date = next_month_start.strftime("%d-%b-%Y")

    print(f"ğŸ“… æœå°‹æ—¥æœŸç¯„åœ: {since_date} è‡³ {before_date}")

    # Create directories
    month_dir = RAW_DIR / target_month
    month_dir.mkdir(parents=True, exist_ok=True)

    try:
        # Connect to IMAP
        mail = connect_imap(config["email"], config["app_password"])

        # Search emails
        email_ids = search_bank_emails(mail, since_date, before_date)

        # Filter by keywords
        matching = filter_by_keywords(mail, email_ids)

        if not matching:
            print("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆçš„éƒµä»¶")
            mail.logout()
            return

        # Download attachments
        matching_ids = [eid for eid, _ in matching]
        downloaded = download_attachments(mail, matching_ids, month_dir)

        print(f"\nğŸ“¦ å·²ä¸‹è¼‰ {len(downloaded)} å€‹é™„ä»¶")

        if args.download_only:
            mail.logout()
            return

        # Parse content and extract transactions
        all_transactions = []
        failed_files = []

        for file_path in downloaded:
            print(f"\nğŸ“„ Parsing: {file_path.name}")
            try:
                text, email_date = parse_content_to_text(file_path)
                transactions = extract_transactions_from_text(text, file_path.name, email_date)

                if transactions:
                    print(f"   âœ… æå– {len(transactions)} ç­†äº¤æ˜“")
                    all_transactions.extend(transactions)
                else:
                    print(f"   âš ï¸ æœªèƒ½è­˜åˆ¥äº¤æ˜“æ ¼å¼")
                    failed_files.append(file_path)

            except Exception as e:
                print(f"   âŒ è§£æå¤±æ•—: {e}")
                failed_files.append(file_path)

        mail.logout()

        if not all_transactions:
            print("\nâŒ æœªèƒ½å¾ä»»ä½•éƒµä»¶æå–äº¤æ˜“")
            if failed_files:
                print(f"   {len(failed_files)} å€‹æª”æ¡ˆéœ€è¦æ‰‹å‹•è™•ç†")
            return

        # Sort by date
        all_transactions.sort(key=lambda x: x.get("æ—¥æœŸ", ""))

        # Add categories
        for tx in all_transactions:
            tx["é¡åˆ¥"] = categorize_transaction(tx["æè¿°"])

        # Generate CSVs
        raw_csv = RAW_DIR / f"{target_month}.csv"
        classified_csv = PROCESSED_DIR / f"{target_month}_classified.csv"
        PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

        # Raw CSV
        with open(raw_csv, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=all_transactions[0].keys())
            writer.writeheader()
            writer.writerows(all_transactions)
        print(f"\nğŸ’¾ åŸå§‹ CSV: {raw_csv}")

        # Classified CSV (same format but with category)
        with open(classified_csv, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=all_transactions[0].keys())
            writer.writeheader()
            writer.writerows(all_transactions)
        print(f"ğŸ’¾ åˆ†é¡ CSV: {classified_csv}")

        # Generate statistics
        stats = generate_statistics(all_transactions)

        # Generate HTML report
        report_path = REPORTS_DIR / f"{target_month}.html"
        REPORTS_DIR.mkdir(parents=True, exist_ok=True)
        generate_html_report(all_transactions, stats, target_month, report_path)

        # Generate Discord summary
        preview_data = all_transactions[:10]
        preview_csv = "\n".join([f"{tx['æ—¥æœŸ']}, {tx['æè¿°'][:20]:20}, ${tx['é‡‘é¡']:.2f}, {tx.get('é¡åˆ¥','')}" for tx in preview_data])
        discord_msg = send_discord_summary(stats, target_month, preview_csv)

        # Save Discord message for later sending
        discord_file = FINANCE_DIR / f"discord_summary_{target_month}.txt"
        with open(discord_file, "w") as f:
            f.write(discord_msg)

        print("\n" + "=" * 50)
        print("âœ… è™•ç†å®Œæˆ!")
        print("=" * 50)
        print(f"\nğŸ“Š CSV é è¦½ (å‰10è¡Œ):")
        print(preview_csv)
        print(f"\nğŸ“Š çµ±è¨ˆæ‘˜è¦:")
        print(f"   ç¸½æ”¶å…¥: ${stats.get('ç¸½æ”¶å…¥', 0):,.2f}")
        print(f"   ç¸½æ”¯å‡º: ${stats.get('ç¸½æ”¯å‡º', 0):,.2f}")
        print(f"   æ·¨é¡: ${stats.get('æ·¨é¡', 0):,.2f}")
        print(f"\nğŸ“ è¼¸å‡ºæª”æ¡ˆ:")
        print(f"   CSV: {raw_csv}")
        print(f"   HTML: {report_path}")
        print(f"   Discord: {discord_file}")

        if failed_files:
            print(f"\nâš ï¸ è§£æå¤±æ•—çš„æª”æ¡ˆ ({len(failed_files)}):")
            for f in failed_files:
                print(f"   - {f.name}")

        if args.test:
            print("\nğŸ§ª æ¸¬è©¦æ¨¡å¼å®Œæˆ - è«‹æª¢æŸ¥ä¸Šè¿°çµæœ")
            print("   ç¢ºèªç„¡èª¤å¾Œï¼ŒåŸ·è¡Œ: openclaw gateway cron create ...")

    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

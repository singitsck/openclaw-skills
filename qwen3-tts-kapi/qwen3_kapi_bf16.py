#!/usr/bin/env python3
"""
Qwen3-TTS Voice Cloning Tool (kapi2800 + bf16)

åŸºæ–¼ kapi2800/qwen3-tts-apple-silicon é …ç›®ï¼Œä½¿ç”¨ bf16 æ¨¡å‹é¿å…éœéŸ³ Bugã€‚

ç”¨æ³•:
    python3 qwen3_kapi_bf16.py --text "ä½ å¥½" --ref_audio voice.wav --ref_text "åƒè€ƒæ–‡æœ¬"
    python3 qwen3_kapi_bf16.py --text "ä½ å¥½" --voice rem  # ä½¿ç”¨é è¨­è²éŸ³

ä½œè€…: é›·å§†
æ—¥æœŸ: 2026-02-22
"""

import os
import sys
import time
import argparse
from pathlib import Path

# é è¨­é…ç½®
DEFAULT_OUTPUT_DIR = os.path.expanduser("~/.openclaw/tts_output")
DEFAULT_VOICES_DIR = os.path.expanduser("~/.openclaw/references")
DEFAULT_MODEL = "mlx-community/Qwen3-TTS-12Hz-1.7B-Base-bf16"

# é è¨­è²éŸ³é…ç½®
PRESET_VOICES = {
    "rem": {
        "name": "é›·å§† (Rem)",
        "audio": "rem/rem_reference.wav",
        "text": "ã“ã“ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚1ã‹ã‚‰â€¦ã„ã„ãˆã€ã‚¼ãƒ­ã‹ã‚‰",
        "description": "Re:Zero é›·å§†è§’è‰²è²éŸ³ï¼Œæ—¥ç³»å¥³åƒ•é¢¨æ ¼"
    },
    "izumi": {
        "name": "å’Œæ³‰å¦ƒæ„› (Izumi Hiyori)",
        "audio": "izumi_hiyori/reference.wav",
        "text": "ã„ã‚„ã‚ã£ã¡ã‚ƒæŒã¡ã‚ã’ã‚‹ã‘ã©ã‚‚ã€æ™®æ®µé€šã‚Šã§ã„ã„ã‚ˆæ™®æ®µé€šã‚Šã§ã€‚ç§ã¨è©±ã™ã¨ãã¿ãŸã„ã«",
        "description": "å’Œæ³‰å¦ƒæ„›è§’è‰²è²éŸ³ï¼Œæ´»æ½‘å¯æ„›çš„å­¸å¦¹é¢¨æ ¼ï¼Œå¸¶æœ‰ã²ã‚ˆã²ã‚ˆå£é ­ç¦ª"
    }
}


def find_voice_file(audio_path: str) -> str:
    """
    æŸ¥æ‰¾è²éŸ³æ–‡ä»¶ï¼Œæ”¯æŒå¤šå€‹è·¯å¾‘ï¼š
    1. ~/.openclaw/references/
    2. è…³æœ¬æ‰€åœ¨ç›®éŒ„çš„ references/
    3. ç•¶å‰å·¥ä½œç›®éŒ„çš„ references/
    """
    # å¯èƒ½çš„è·¯å¾‘
    possible_paths = [
        os.path.join(DEFAULT_VOICES_DIR, audio_path),
        os.path.join(os.path.dirname(__file__), "references", audio_path),
        os.path.join(os.path.dirname(os.path.abspath(__file__)), "references", audio_path),
        os.path.join(os.getcwd(), "references", audio_path),
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›ç¬¬ä¸€å€‹è·¯å¾‘ï¼ˆè®“å¾ŒçºŒå ±éŒ¯ï¼‰
    return possible_paths[0]


def check_model_downloaded(model_id: str) -> bool:
    """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è¼‰"""
    from huggingface_hub import try_to_load_from_cache
    
    try:
        result = try_to_load_from_cache(model_id, "config.json")
        return result is not None and str(result) != "_CACHED_NO_EXIST_"
    except:
        return False


def download_model(model_id: str):
    """ä¸‹è¼‰æ¨¡å‹"""
    from huggingface_hub import snapshot_download
    
    print(f"ğŸ“¥ ä¸‹è¼‰æ¨¡å‹: {model_id}")
    print("é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜ï¼ˆç´„ 4GBï¼‰...")
    
    snapshot_download(repo_id=model_id, local_files_only=False)
    print("âœ… æ¨¡å‹ä¸‹è¼‰å®Œæˆ")


def generate_voice(
    text: str,
    ref_audio: str,
    ref_text: str,
    output_path: str = None,
    model_id: str = DEFAULT_MODEL,
    verbose: bool = True
) -> str:
    """
    ç”ŸæˆèªéŸ³
    
    Args:
        text: è¦åˆæˆçš„æ–‡æœ¬
        ref_audio: åƒè€ƒéŸ³é »è·¯å¾‘
        ref_text: åƒè€ƒéŸ³é »å°æ‡‰çš„æ–‡æœ¬
        output_path: è¼¸å‡ºè·¯å¾‘ï¼ˆå¯é¸ï¼‰
        model_id: æ¨¡å‹ ID
        verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°ä¿¡æ¯
    
    Returns:
        ç”Ÿæˆçš„éŸ³é »æ–‡ä»¶è·¯å¾‘
    """
    from mlx_audio.tts.utils import load_model
    from mlx_audio.tts.generate import generate_audio
    
    # æª¢æŸ¥åƒè€ƒéŸ³é »
    if not os.path.exists(ref_audio):
        raise FileNotFoundError(f"åƒè€ƒéŸ³é »ä¸å­˜åœ¨: {ref_audio}")
    
    # æª¢æŸ¥ä¸¦ä¸‹è¼‰æ¨¡å‹
    if not check_model_downloaded(model_id):
        if verbose:
            print(f"ğŸ” æ¨¡å‹æœªä¸‹è¼‰ï¼Œé–‹å§‹ä¸‹è¼‰...")
        download_model(model_id)
    
    if verbose:
        print(f"ğŸ™ï¸ Qwen3-TTS Voice Cloning")
        print(f"=" * 60)
        print(f"ğŸ“ æ–‡æœ¬: {text}")
        print(f"ğŸ”Š åƒè€ƒ: {ref_audio}")
        print(f"ğŸ¤– æ¨¡å‹: {model_id}")
        print()
        print("ğŸ“¦ è¼‰å…¥æ¨¡å‹...")
    
    # è¼‰å…¥æ¨¡å‹
    model = load_model(model_id)
    
    if verbose:
        print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
        print()
        print("ğŸ™ï¸ ç”Ÿæˆä¸­...")
    
    # æº–å‚™è¼¸å‡º
    if output_path is None:
        os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)
        output_prefix = os.path.join(DEFAULT_OUTPUT_DIR, f"qwen3_{int(time.time())}")
    else:
        output_prefix = output_path.replace(".wav", "")
    
    # ç”Ÿæˆ
    start_time = time.time()
    generate_audio(
        model=model,
        text=text,
        ref_audio=ref_audio,
        ref_text=ref_text,
        file_prefix=output_prefix,
        audio_format="wav"
    )
    elapsed = time.time() - start_time
    
    output_file = f"{output_prefix}_000.wav"
    
    if verbose:
        print()
        print(f"âœ… ç”Ÿæˆå®Œæˆ!")
        print(f"â±ï¸ è€—æ™‚: {elapsed:.1f}ç§’")
        print(f"ğŸµ è¼¸å‡º: {output_file}")
    
    return output_file


def main():
    parser = argparse.ArgumentParser(
        description="Qwen3-TTS èªéŸ³å…‹éš†å·¥å…· (kapi2800 + bf16)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s --text "ä½ å¥½" --ref_audio voice.wav --ref_text "åƒè€ƒæ–‡æœ¬"
  %(prog)s --text "ä¸»äººå¥½" --voice rem --output ~/rem.wav
  %(prog)s --list-voices
        """
    )
    
    parser.add_argument("--text", "-t", required=True, help="è¦åˆæˆçš„æ–‡æœ¬")
    parser.add_argument("--ref_audio", "-a", help="åƒè€ƒéŸ³é »è·¯å¾‘")
    parser.add_argument("--ref_text", "-r", help="åƒè€ƒéŸ³é »å°æ‡‰çš„æ–‡æœ¬")
    parser.add_argument("--voice", "-v", help=f"ä½¿ç”¨é è¨­è²éŸ³: {', '.join(PRESET_VOICES.keys())}")
    parser.add_argument("--output", "-o", help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘ï¼ˆå¯é¸ï¼‰")
    parser.add_argument("--model", "-m", default=DEFAULT_MODEL, help=f"æ¨¡å‹IDï¼ˆé»˜èª: {DEFAULT_MODEL}ï¼‰")
    parser.add_argument("--list-voices", action="store_true", help="åˆ—å‡ºæ‰€æœ‰é è¨­è²éŸ³")
    parser.add_argument("--quiet", "-q", action="store_true", help="å®‰éœæ¨¡å¼")
    
    args = parser.parse_args()
    
    # åˆ—å‡ºé è¨­è²éŸ³
    if args.list_voices:
        print("ğŸ­ å¯ç”¨é è¨­è²éŸ³:")
        for key, info in PRESET_VOICES.items():
            print(f"  {key}: {info['name']}")
            print(f"    {info['description']}")
            print()
        return
    
    # è™•ç†é è¨­è²éŸ³
    if args.voice:
        if args.voice not in PRESET_VOICES:
            print(f"âŒ æœªçŸ¥è²éŸ³: {args.voice}")
            print(f"å¯ç”¨è²éŸ³: {', '.join(PRESET_VOICES.keys())}")
            sys.exit(1)
        
        voice_info = PRESET_VOICES[args.voice]
        ref_audio = find_voice_file(voice_info["audio"])
        ref_text = voice_info["text"]
    else:
        if not args.ref_audio or not args.ref_text:
            print("âŒ è«‹æä¾› --ref_audio å’Œ --ref_textï¼Œæˆ–ä½¿ç”¨ --voice é¸æ“‡é è¨­è²éŸ³")
            sys.exit(1)
        ref_audio = args.ref_audio
        ref_text = args.ref_text
    
    # ç”Ÿæˆ
    try:
        output_file = generate_voice(
            text=args.text,
            ref_audio=ref_audio,
            ref_text=ref_text,
            output_path=args.output,
            model_id=args.model,
            verbose=not args.quiet
        )
        
        if args.quiet:
            print(output_file)
        
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
